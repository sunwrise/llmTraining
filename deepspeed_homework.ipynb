{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a67f8b-29dc-4d72-92ac-d3455ae4bc62",
   "metadata": {},
   "source": [
    "### 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7eb78c-bf69-41d4-8b12-8bab09b1f452",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch>=2.1.2 in /root/miniconda3/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.1.2+cu121)\n",
      "Collecting transformers\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/85/f6/c5065913119c41ecad148c34e3a861f719e16b89a522287213698da911fc/transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ffmpeg\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ffmpeg-python\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting timm\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/01/a5/eeb717242343d9ca34e7de554a6c08d96a0cfc7005ece4f847b1753581a6/timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/74/4d/63b033169534f0742b7fe13957118cae08c83b04bfde46511f397872e2e7/datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/3f/61/047b353f0ad550226ef962da182b4a09b689eb6df6bd84a03e44f9ee95bb/scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b3/b3/3102c3a4abca1093e50cfec2213102a1c65c0b318a4431395d0121e6e690/pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/07/63/168af5aa8dbda9c23ad774a4c1d311cfe220c634e0d05a3a82a7cae01bd8/peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c8/14/73c3d62e709c2ace755c826997b12f883f3cb6b138dec63ac1e2a68cd910/accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting autoawq\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f7/b5/38291e9ef67ef7d6146339111298fab4dd76778ca59a3511af2663ed4b9c/autoawq-0.1.8-cp310-cp310-manylinux2014_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting optimum\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/cc/a8/9b311809c51d5c9bc5a495edc6c8873c92db69cfecf69d4ec3c845e9804f/optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting auto-gptq\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/09/b2/c964b7f286ce5f782c1be0b46700091daa60a121b41e06d9a59047b45e57/auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes>0.39.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9b/63/489ef9cd7a33c1f08f1b2be51d1b511883c5e34591aaa9873b30021cd679/bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jiwer\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0d/4f/ee537ab20144811dd99321735ff92ef2b3a3230b77ed7454bed4c44d21fc/jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c1/07/7591f4efd29e65071c3a61b53725036ea8f73366a4920a481ebddaf8d0ca/soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/10/17/1d00f5ee2577d9c10c238c318b1fe6f6142a989c77277b6163d9549e3f93/langchain-0.1.6-py3-none-any.whl (811 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/40/c2/68c58aabbe821866e9a11a3776c9d36fd4416e812ab4ab58b531e82bd3da/gradio-4.18.0-py3-none-any.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (2023.12.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.10/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (23.2)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d0/ba/b2254fafc7f5fdc98a2fa4d5a5eeb029fbf9589ec87f2c230c3ac0a1dd53/safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/28/03/7d3c7153113ec59cfb31e3b8ee773f5f420a0dd7d26d40442542b96675c3/huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (1.26.3)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1e/54/a3451cdf47760a0f671e07ae69fdff00a1dc074db869a1655096c592fd0f/tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/81/8a/96a62ce98e8ff1b16db56fde3debc8a571f6b7ea42ee137eb0d995cdfa26/regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting future\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/8f/2e/cf6accf7415237d6faeeebdc7832023c90e0282aa16fd3263db0eb4715ec/future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /root/miniconda3/lib/python3.10/site-packages (from timm->-r requirements.txt (line 5)) (0.16.2+cu121)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d4/ca/ef67abb77f9dd51a0d3ff7fcebff58296068a046d7da352b9548070005ed/pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/93/40/d3decda219ebd5410eba627601d537ec3782efbcadba308e9ce381cc0b71/aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow-hotfix\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting xxhash\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f5/aa/8e6071a5e4dca4ec68b5b22e4991ee74c59c5d372112b9c236ec1faff57d/scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a3/fb/52b62131e21b24ee297e4e95ed41eba29647dad0e0051a92bb66b43c70ff/tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.10/site-packages (from peft->-r requirements.txt (line 10)) (5.9.7)\n",
      "Collecting attributedict\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/de/db/337b36e8d85a07293f5a792644fa972b53a52b13587f484c627009206697/attributedict-0.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting tabulate\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting toml\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: protobuf in /root/miniconda3/lib/python3.10/site-packages (from autoawq->-r requirements.txt (line 12)) (4.23.4)\n",
      "Collecting lm-eval\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/49/2d/39f7a25ab663cb45cfc7773b85980f01df44853cc427d00dce94c90b43e6/lm_eval-0.4.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting texttable\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/7f/e5/323dc813b3e1339305f888d035e2f3725084fc4dcf051995b366dd26cc90/sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gekko\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/57/d1/cdb977d024b2d7212bea0d6aa939dfdd15c6fb22deacbfb07fd9d8a77734/gekko-1.0.6-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Collecting rapidfuzz<4,>=3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/02/39/3f94121e21b78e0a2699b272a8906ee5eb6f9d70082d90784464b0a4fcc8/rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click<9.0.0,>=8.1.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /root/miniconda3/lib/python3.10/site-packages (from soundfile>=0.12.1->-r requirements.txt (line 17)) (1.15.1)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/31/f7/d95b816c47dca6a068305fb7176b8c8d2c94bbc6cce6dcc296c6cf98660f/soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1a/a5/5174dac3957ac412e80a00f30b6507031fcab7000afc9ea0ac413bddcff2/pooch-1.8.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lazy-loader>=0.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting msgpack>=1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/46/95/d0440400485eab1bf50f1efe5118967b539f3191d994c3dfc220657594cd/msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.51.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/73/d5/d359cece32302442c8ea9742b1324c4eda689fd54281eb3144f520c81f6d/numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /root/miniconda3/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 18)) (5.1.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/db/dc/afecbd9650f486889181c6d1a0d675b580c06253ea7e304588e4c7485bdb/pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2c/e6/967cd898cbce485c385d4cd644195f906b2571f9393dc1537019a821a8a6/SQLAlchemy-2.0.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/71/41/02beb3f8e22c258e0643c8b1e2ccf0d47888edcaae6895580a38f708b9ee/langsmith-0.0.90-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.18\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bf/b4/1b1b22ab0c57320c5476b735cfe1500e49ddc4425df9e4c2e569e4c4472e/langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.22\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c8/69/f9cd4ef398973830afe697417070d712ef1fbb3b9a768b8599f555deb687/langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typer[all]<1.0,>=0.9\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bf/0e/c68adf10adda05f28a6ed7b9f4cd7b8e07f641b44af88ba72d9c89e4de7a/typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson~=3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/00/a6/144bfa40294a4401076f64b00834adda56a9c995280081e41f081ac5d909/orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruff>=0.1.7\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/70/d3/67fdaff63c3092fb667573d6b69fe601020212078b68adedcb821ad4dfcd/ruff-0.2.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c7/f3/29caa83f5795b20ed3aca357c648f3ae995ff6ff08e38b22387017abbdc5/uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9a/06/49b275a312eb207e2a2718a7414dedfded05088437352b67aaa9a355f948/ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: markupsafe~=2.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 20)) (2.1.3)\n",
      "Collecting altair<6.0,>=4.2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c5/e4/7fcceef127badbb0d644d730d992410e4f3799b295c9964a172f92a469c7/altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bf/97/60351307ab4502908d29f64f2801a36709a3f1888447bb328bc373d6ca0e/fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib-resources<7.0,>=1.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Collecting gradio\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1f/2d/225bc5f6dd1fbee4fa4852eba8a319b56d1a7fd8be91c059384f4593249f/gradio-4.17.0-py3-none-any.whl (16.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.9.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e5/3d/4e491cdd9b9b7e74361dc53a4a0f4ba3e421091bb95bc75701b2d34091bc/gradio_client-0.9.0-py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles<24.0,>=22.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 20)) (3.8.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /root/miniconda3/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 20)) (10.2.0)\n",
      "Collecting python-multipart\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c0/3e/9fbfd74e7f5b54f653f7ca99d44ceb56e718846920162165061c4c22b71a/python_multipart-0.0.8-py3-none-any.whl (22 kB)\n",
      "Collecting tomlkit==0.12.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/68/4f/12207897848a653d03ebbf6775a29d949408ded5f99b2d87198bc5c93508/tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Collecting semantic-version~=2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting websockets<12.0,>=10.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/58/0a/7570e15661a0a546c3a1152d95fe8c05480459bab36247f0acbf41f01a41/websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (23.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/33/62/2c9085e571318d51212a6914566fe41dd0e33d7f268f7e2f23dcd3f06c56/multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ec/25/0c87df2e53c0c5d90f7517ca0ff7aca78d050a8ec4d32c4278e8c0e52e51/frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c3/a0/0ade1409d184cbc9e85acd403a386a7c0563b92ff0f26d138ff9e86e48b4/yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /root/miniconda3/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 20)) (4.20.0)\n",
      "Requirement already satisfied: toolz in /root/miniconda3/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 20)) (0.12.0)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements.txt (line 17)) (2.21)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/57/e9/4368d49d3b462da16a3bac976487764a84dd85cef97232c7bd61f5bdedf3/marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 19)) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /root/miniconda3/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 19)) (4.2.0)\n",
      "Collecting langsmith<0.1,>=0.0.83\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/94/99/762b50b229516dd133e09c16213736b88d50d75e262b976e20cc244280ed/langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 20)) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 20)) (4.47.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 20)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 20)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 20)) (3.1.1)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2b/01/764489e364948f52aa7cb958a91a8dafd489357d2401f66946542bbc1764/llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.5.0 in /root/miniconda3/lib/python3.10/site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 18)) (4.1.0)\n",
      "Collecting pydantic-core==2.16.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/50/5e/2978d9f0e8d0cfd78e22115c028a41e0599e3d684e5aef7ed9bd18fcbd0c/pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/24/35/945d5b10648fec9b20bcc6df8952d20bb3bba76413cd71c1fdbee98f5616/greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting colorama<0.5.0,>=0.4.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting rich<14.0.0,>=10.11.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/be/be/1520178fa01eabe014b16e72a952b9f900631142ccd03dc36cf93e30c1ce/rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shellingham<2.0.0,>=1.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting codecov>=2.0.15\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/af/02/18785edcdf6266cdd6c6dc7635f1cbeefd9a5b4c3bb8aff8bd681e9dd095/codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Collecting colour-runner>=0.0.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d4/82/ce3250026add1910739dcabc796571ad1d182cb47332716c8bb96ee5d624/colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting tox>=3.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f0/52/38a555b5d86be75ae198d4fc722b6581aa735a91ee260a4398fd9a1b7bf6/tox-4.12.1-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting coverage>=4.5.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/49/d5/9d66fd984979b58927588efb0398953acbdb4c45eb7cfcd74fa9b8d51d12/coverage-7.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.0/234.0 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rootpath>=0.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4f/f9/959835686c78b7a95d8d806a97fa0be020c2deccb96de2b60659744319b9/rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
      "Collecting inspecta>=0.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/03/aa/5ad8e223fa564d474b465771710b8b7b23896b59651cf115f510bcfda3ee/inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n",
      "Collecting deepdiff>=3.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/5a/8f/a9d39ec15f40e8169cb134317824ee4618b864b2e4b91a9b310d3ef94729/deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/eb/f7/372e3953b6e6fbfe0b70a1bb52612eae16e943f4288516480860fcd4ac41/starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /root/miniconda3/lib/python3.10/site-packages (from httpx->gradio->-r requirements.txt (line 20)) (1.3.0)\n",
      "Collecting jsonlines\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting numexpr\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4a/39/cc88cdade7fb8e409efb63b79c22cfbea7c9c15249e375dfbaf86984dece/numexpr-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (375 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.2/375.2 kB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score>=0.0.4\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e2/c5/9136736c37022a6ad27fea38f3111eb8f02fe75d067f9a985cc358653102/rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytablewriter\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/06/74/b39b823ee7dba155b117634e62733a0dfdfe5aa100a553b435062cee2062/pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybind11>=2.6.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zstandard\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c9/79/07f6d2670fa2708ae3b79aabb82da78e9cbdb08d9bafadf8638d356775ff/zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlitedict\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/12/9a/7620d1e9dcb02839ed6d4b14064e609cdd7a8ae1e47289aa0456796dd9ca/sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm-multiprocess\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/25/7e/0d889fc6c84e3df6b69aaafe893fc77f69b3d968ac9ce574d1c62c688050/tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Collecting sacrebleu>=1.5.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/de/ea/025db0a39337b63d4728a900d262c39c3029b0fe76a9876ce6297b1aa6a0/sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.10/site-packages (from sympy->torch>=2.1.2->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 19)) (1.2.0)\n",
      "Requirement already satisfied: pygments in /root/miniconda3/lib/python3.10/site-packages (from colour-runner>=0.0.5->attributedict->autoawq->-r requirements.txt (line 12)) (2.17.2)\n",
      "Collecting blessings\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 20)) (0.16.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 20)) (0.32.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 20)) (2023.12.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /root/miniconda3/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq->-r requirements.txt (line 12)) (2.0.0)\n",
      "Collecting nltk\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lxml\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/25/5c/979167df4ca5a1c308105bb1590412c54bd1b0baa1883212f39cb42d4fcd/lxml-5.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting portalocker\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /root/miniconda3/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq->-r requirements.txt (line 12)) (2.0.1)\n",
      "Collecting virtualenv>=20.25\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/83/22/54b1180756d2d6194bcafb7425d437c3034c4bff92129c3e1e633079e2c4/virtualenv-20.25.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pluggy>=1.3\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a5/5b/0cc789b59e8cc1bf288b38111d002d8c5917123194d45b29dcdac64723cc/pluggy-1.4.0-py3-none-any.whl (20 kB)\n",
      "Collecting pyproject-api>=1.6.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/cf/b4/39eea50542e50e93876ebc09c4349a9c9eee9f6b9c9d30f88c7dc5433db8/pyproject_api-1.6.1-py3-none-any.whl (12 kB)\n",
      "Collecting chardet>=5.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools>=5.3.2 in /root/miniconda3/lib/python3.10/site-packages (from tox>=3.0.0->attributedict->autoawq->-r requirements.txt (line 12)) (5.3.2)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0c/ab/673cce13ab635fd755d206b18c0a371ef6e28ddbe25fadba9ae6c59f22a5/pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
      "Collecting tabledata<2,>=1.3.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/06/e2/96b10ebc00d20b55967200e3d95c2137d91f58af1af672627683431c9d5c/tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c2/0f/726229136022b154895138bb10ba35e8435c4143f614cb5ad4d4e3fc21ec/mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/34/d0/8a701df46bf546fd155da02934b0bb2ac6ad4186e29f4a3297e744ab259d/tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
      "Collecting typepy[datetime]<2,>=1.3.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f1/10/0d6dc654bb4e0eca017bbaf43a315b464c888576a68a2883cd4a74bd1b6b/typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /root/miniconda3/lib/python3.10/site-packages (from pytablewriter->lm-eval->autoawq->-r requirements.txt (line 12)) (65.5.0)\n",
      "Collecting DataProperty<2,>=1.0.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b1/3b/90ebd66ad57c588d6087e86e327436343e9cc60776a9445b79c6e80a022d/DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/8e/41/9307e4f5f9976bc8b7fea0b66367734e8faf3ec84bc0d412d8cfabbb66cd/distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg, ffmpy, future, rouge-score, sqlitedict\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=e44e4052498252df306f36b1868ad5a69da3a0bb653916b1985de4421cf63660\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/48/f2/1006e7e489c319c1f753c271267fc63753737ff134c3d765e9\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=b192253cb31842978e5de2aff038d0235606820f01ae7c8f0e858b14a1d70614\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/41/c6/e57ccda88373aaf54488799e42850986d5ad5164862fa035fa\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=874ff0569c3ef4c63817b95d13e0d4c3c83097b34a552af2159dd65b907863bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/54/16/2ab500319d13efeeee4b2007aab5a01589dc775fb1a1f617c5\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24936 sha256=8c77e40438c5abdd3069c03eb4e8491c0177e2817fb6d99ce80bf421e51f3b8c\n",
      "  Stored in directory: /root/.cache/pip/wheels/df/8b/4d/81c07689350704f4325b04e4ae12323eb7becea0d9f9a581ba\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=9dc79adcb890690e91fbaf4e31a814f72ffc5615cc95c7d6f0d7b2b779d5058c\n",
      "  Stored in directory: /root/.cache/pip/wheels/c7/f6/d9/47c29be48baf942eba15e861ef0b05a12292ea1d379b68abc2\n",
      "Successfully built ffmpeg ffmpy future rouge-score sqlitedict\n",
      "Installing collected packages: texttable, sqlitedict, sentencepiece, pytz, pydub, ffmpy, ffmpeg, distlib, zstandard, xxhash, websockets, virtualenv, tzdata, tomlkit, toml, threadpoolctl, termcolor, tenacity, tcolorpy, tabulate, soxr, shellingham, semantic-version, scipy, safetensors, ruff, rouge, regex, rapidfuzz, python-multipart, pyproject-api, pydantic-core, pybind11, pyarrow-hotfix, pyarrow, portalocker, pluggy, pathvalidate, orjson, ordered-set, numexpr, mypy-extensions, multidict, msgpack, mdurl, marshmallow, lxml, llvmlite, lazy-loader, jsonpatch, jsonlines, joblib, importlib-resources, humanfriendly, h11, greenlet, gekko, future, fsspec, frozenlist, dill, coverage, colorama, click, chardet, blessings, audioread, async-timeout, annotated-types, aiofiles, yarl, uvicorn, typing-inspect, typer, tqdm-multiprocess, tox, starlette, SQLAlchemy, soundfile, scikit-learn, sacrebleu, responses, pydantic, pooch, pandas, numba, nltk, multiprocess, mbstrdecoder, markdown-it-py, jiwer, huggingface-hub, httpcore, ffmpeg-python, deepdiff, colour-runner, coloredlogs, codecov, bitsandbytes, aiosignal, typepy, tokenizers, rouge-score, rootpath, rich, librosa, langsmith, httpx, fastapi, dataclasses-json, aiohttp, accelerate, transformers, timm, langchain-core, inspecta, gradio-client, altair, peft, langchain-community, gradio, datasets, DataProperty, attributedict, tabledata, optimum, langchain, evaluate, auto-gptq, pytablewriter, lm-eval, autoawq\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.0.0\n",
      "    Uninstalling pluggy-1.0.0:\n",
      "      Successfully uninstalled pluggy-1.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "Successfully installed DataProperty-1.0.1 SQLAlchemy-2.0.25 accelerate-0.27.0 aiofiles-23.2.1 aiohttp-3.9.3 aiosignal-1.3.1 altair-5.2.0 annotated-types-0.6.0 async-timeout-4.0.3 attributedict-0.3.0 audioread-3.0.1 auto-gptq-0.6.0 autoawq-0.1.8 bitsandbytes-0.42.0 blessings-1.7 chardet-5.2.0 click-8.1.7 codecov-2.1.13 colorama-0.4.6 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.4.1 dataclasses-json-0.6.4 datasets-2.17.0 deepdiff-6.7.1 dill-0.3.8 distlib-0.3.8 evaluate-0.4.1 fastapi-0.109.2 ffmpeg-1.4 ffmpeg-python-0.2.0 ffmpy-0.3.1 frozenlist-1.4.1 fsspec-2023.10.0 future-0.18.3 gekko-1.0.6 gradio-4.17.0 gradio-client-0.9.0 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 huggingface-hub-0.20.3 humanfriendly-10.0 importlib-resources-6.1.1 inspecta-0.1.3 jiwer-3.0.3 joblib-1.3.2 jsonlines-4.0.0 jsonpatch-1.33 langchain-0.1.6 langchain-community-0.0.19 langchain-core-0.1.22 langsmith-0.0.87 lazy-loader-0.3 librosa-0.10.1 llvmlite-0.42.0 lm-eval-0.4.1 lxml-5.1.0 markdown-it-py-3.0.0 marshmallow-3.20.2 mbstrdecoder-1.1.3 mdurl-0.1.2 msgpack-1.0.7 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 nltk-3.8.1 numba-0.59.0 numexpr-2.9.0 optimum-1.16.2 ordered-set-4.1.0 orjson-3.9.13 pandas-2.2.0 pathvalidate-3.2.0 peft-0.8.2 pluggy-1.4.0 pooch-1.8.0 portalocker-2.8.2 pyarrow-15.0.0 pyarrow-hotfix-0.6 pybind11-2.11.1 pydantic-2.6.1 pydantic-core-2.16.2 pydub-0.25.1 pyproject-api-1.6.1 pytablewriter-1.2.0 python-multipart-0.0.8 pytz-2024.1 rapidfuzz-3.6.1 regex-2023.12.25 responses-0.18.0 rich-13.7.0 rootpath-0.1.1 rouge-1.0.1 rouge-score-0.1.2 ruff-0.2.1 sacrebleu-2.4.0 safetensors-0.4.2 scikit-learn-1.4.0 scipy-1.12.0 semantic-version-2.10.0 sentencepiece-0.1.99 shellingham-1.5.4 soundfile-0.12.1 soxr-0.3.7 sqlitedict-2.1.0 starlette-0.36.3 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.4 tenacity-8.2.3 termcolor-2.4.0 texttable-1.7.0 threadpoolctl-3.2.0 timm-0.9.12 tokenizers-0.15.1 toml-0.10.2 tomlkit-0.12.0 tox-4.12.1 tqdm-multiprocess-0.0.11 transformers-4.37.2 typepy-1.3.2 typer-0.9.0 typing-inspect-0.9.0 tzdata-2023.4 uvicorn-0.27.0.post1 virtualenv-20.25.0 websockets-11.0.3 xxhash-3.4.1 yarl-1.9.4 zstandard-0.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcf9144-b8c0-49e0-b506-e15f4dedc193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "CUDA_VISIBLE_DEVICES=0 \n",
    "print(torch.cuda.get_device_capability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48cef3f-1602-44fa-bda6-ac1400b058d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d72333-7b46-4659-912a-e802be796808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 4090', major=8, minor=9, total_memory=24217MB, multi_processor_count=128)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa7886-fa8b-4eaf-842b-67b59a000590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在终端运行如下指令，安装deepspeed\n",
    "git clone https://github.com/microsoft/DeepSpeed/\n",
    "cd DeepSpeed\n",
    "rm -rf build\n",
    "TORCH_CUDA_ARCH_LIST=\"8.9\" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 pip install . \\\n",
    "--global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v \\\n",
    "--disable-pip-version-check 2>&1 | tee build.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7c22-2803-403b-8a76-3ffdb58f6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSpeed ZeRO-2 模式单 GPU 训练翻译模型（T5-Small）\n",
    "deepspeed --num_gpus=1 ../LLM-quickstart/deepspeed/translation/run_translation.py \\\n",
    "--deepspeed ../LLM-quickstart/deepspeed/config/ds_config_zero2.json \\\n",
    "--model_name_or_path t5-small --per_device_train_batch_size 1 \\\n",
    "--output_dir output_dir --overwrite_output_dir --fp16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro\n",
    "\n",
    "# 运行后报错：\n",
    "# ImportError: This example requires a source install from HuggingFace Transformers (see `https://huggingface.co/docs/transformers/installation#install-from-source`), but the version found is 4.37.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076f89d-7a48-4e31-8abf-75bf9a937701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 源代码安装Transformers\n",
    "pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd67f6-05e8-4a37-a54e-924dea388fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新运行DeepSpeed ZeRO-2 模式单 GPU 训练翻译模型（T5-Small）\n",
    "deepspeed --num_gpus=1 ../LLM-quickstart/deepspeed/translation/run_translation.py \\\n",
    "--deepspeed ../LLM-quickstart/deepspeed/config/ds_config_zero2.json \\\n",
    "--model_name_or_path t5-small --per_device_train_batch_size 1 \\\n",
    "--output_dir output_dir --overwrite_output_dir --fp16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b89ee-4dd5-4532-b638-aa45f1454130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练结果\n",
    "[INFO|tokenization_t5_fast.py:191] 2024-02-10 21:06:01,282 >> Copy vocab file to output_dir/spiece.model\n",
    "***** train metrics *****\n",
    "  epoch                    =        1.0\n",
    "  train_loss               =     0.9435\n",
    "  train_runtime            = 0:00:47.39\n",
    "  train_samples            =        500\n",
    "  train_samples_per_second =      10.55\n",
    "  train_steps_per_second   =      10.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d54377-c247-4367-85db-4c4ed72fa35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先运行命令改变模型默认存储地址，要关注命令的运行环境，灵活更改路径\n",
    "export HF_DATASETS_CACHE=\"/root/autodl-tmp/datasets_cache/\"\n",
    "export HF_HOME=\"/root/autodl-tmp/cache/\"\n",
    "export HUGGINGFACE_HUB_CACHE=\"/root/autodl-tmp/hub_cache/\"\n",
    "export TRANSFORMERS_CACHE=\"/root/autodl-tmp/transform_cache/\"\n",
    "export HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5173b-8346-4840-884e-4201b39dcde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置网络环境\n",
    "source /etc/network_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a865b5c-133d-42d3-a5e8-fcdc944f83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSpeed ZeRO-3 模式单 GPU 训练翻译模型（T5-3b）,经测试60g内存是不行的，至少要90g内存。\n",
    "# https://github.com/microsoft/DeepSpeed/issues/3160\n",
    "deepspeed --num_gpus=1 LLM-quickstart/deepspeed/translation/run_translation.py \\\n",
    "--deepspeed LLM-quickstart/deepspeed/config/ds_config_zero3.json \\\n",
    "--model_name_or_path t5-3b --per_device_train_batch_size 1 \\\n",
    "--output_dir output_dir --overwrite_output_dir --fp16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro\n",
    "\n",
    "# 报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46da4a-e553-4772-aa97-c5bcb6192536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置ds_config_zero3.json的参数，其中\n",
    "\n",
    "# \"stage3_prefetch_bucket_size\": 这个参数控制每个GPU上用于预取数据的最大样本数量。\n",
    "# 你已经将其设置为 32，可以尝试进一步减小这个值，例如设置为 16 或更小，以减少内存消耗。\n",
    "\n",
    "# \"stage3_param_persistence_threshold\": 这个参数控制在多少步骤之后，模型参数会被持久化到硬盘上。\n",
    "# 你已经将其设置为 10000，可以尝试增加这个阈值，例如设置为 20000 或更高，以减少内存消耗。\n",
    "\n",
    "# \"stage3_max_live_parameters\": 这个参数控制每个GPU上最大允许的参数数量。\n",
    "# 你已经将其设置为 1e4，可以尝试进一步减小这个值，例如设置为 5000 或更小，以减少内存消耗。\n",
    "\n",
    "# \"stage3_max_reuse_distance\": 这个参数控制参数的最大重用距离。\n",
    "# 你已经将其设置为 1e4，可以尝试进一步减小这个值，例如设置为 5000 或更小，以减少内存消耗。\n",
    "\n",
    "# \"stage3_gather_16bit_weights_on_model_save\": 这个参数控制在模型保存时是否将参数转换为 16 位精度。你已经将其设置为 false，\n",
    "# 这是合理的，因为不需要额外的内存来保存参数。\n",
    "\n",
    "# 对应修改的参数如下：\n",
    "stage3_prefetch_bucket_size 16\n",
    "stage3_param_persistence_threshold 20000\n",
    "stage3_max_live_parameters 5000\n",
    "stage3_max_reuse_distance 5000\n",
    "stage3_gather_16bit_weights_on_model_save false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461f52e-5feb-45b1-a18c-10ce3ffdad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时更新命令\n",
    "# DeepSpeed ZeRO-3 模式单 GPU 训练翻译模型（T5-3b）,经测试60g内存是不行的，至少要90g内存。\n",
    "# https://github.com/microsoft/DeepSpeed/issues/3160\n",
    "# bf16,为防止Exception: Current loss scale already at minimum - cannot decrease scale anymore. Exiting run.\n",
    "# https://github.com/microsoft/DeepSpeedExamples/issues/418\n",
    "deepspeed --num_gpus=1 LLM-quickstart/deepspeed/translation/run_translation.py \\\n",
    "--deepspeed LLM-quickstart/deepspeed/config/ds_config_zero3.json \\\n",
    "--model_name_or_path t5-3b --per_device_train_batch_size 1 \\\n",
    "--output_dir autodl-tmp/output_dir --overwrite_output_dir --bf16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb05926-4454-46c1-b3b9-42ba1a36d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root@autodl-container-a5904787c3-9bffb005:~# deepspeed --num_gpus=1 LLM-quickstart/deepspeed/translation/run_translation.py \\\n",
    "--deepspeed LLM-quickstart/deepspeed/config/ds_config_zero3.json \\\n",
    "--model_name_or_path t5-3b --per_device_train_batch_size 1 \\\n",
    "--output_dir output_dir --overwrite_output_dir --bf16 \\\n",
    "--do_train --max_train_samples 500 --num_train_epochs 1 \\\n",
    "--dataset_name wmt16 --dataset_config \"ro-en\" \\\n",
    "--source_lang en --target_lang ro\n",
    "/root/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
    "  warnings.warn(\n",
    "[2024-02-11 02:32:52,376] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
    "[2024-02-11 02:32:53,106] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
    "[2024-02-11 02:32:53,106] [INFO] [runner.py:568:main] cmd = /root/miniconda3/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None LLM-quickstart/deepspeed/translation/run_translation.py --deepspeed LLM-quickstart/deepspeed/config/ds_config_zero3.json --model_name_or_path t5-3b --per_device_train_batch_size 1 --output_dir output_dir --overwrite_output_dir --bf16 --do_train --max_train_samples 500 --num_train_epochs 1 --dataset_name wmt16 --dataset_config ro-en --source_lang en --target_lang ro\n",
    "/root/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
    "  warnings.warn(\n",
    "[2024-02-11 02:32:56,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
    "[2024-02-11 02:32:57,246] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.17.1-1+cuda12.1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.17.1-1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.17.1-1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.17.1-1+cuda12.1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.17.1-1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:163:main] dist_world_size=1\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
    "[2024-02-11 02:32:57,247] [INFO] [launch.py:253:main] process 4518 spawned with command: ['/root/miniconda3/bin/python', '-u', 'LLM-quickstart/deepspeed/translation/run_translation.py', '--local_rank=0', '--deepspeed', 'LLM-quickstart/deepspeed/config/ds_config_zero3.json', '--model_name_or_path', 't5-3b', '--per_device_train_batch_size', '1', '--output_dir', 'output_dir', '--overwrite_output_dir', '--bf16', '--do_train', '--max_train_samples', '500', '--num_train_epochs', '1', '--dataset_name', 'wmt16', '--dataset_config', 'ro-en', '--source_lang', 'en', '--target_lang', 'ro']\n",
    "/root/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
    "  warnings.warn(\n",
    "[2024-02-11 02:33:01,503] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
    "[2024-02-11 02:33:01,697] [INFO] [comm.py:637:init_distributed] cdb=None\n",
    "[2024-02-11 02:33:01,697] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
    "02/11/2024 02:33:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
    "02/11/2024 02:33:01 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
    "_n_gpu=1,\n",
    "adafactor=False,\n",
    "adam_beta1=0.9,\n",
    "adam_beta2=0.999,\n",
    "adam_epsilon=1e-08,\n",
    "auto_find_batch_size=False,\n",
    "bf16=True,\n",
    "bf16_full_eval=False,\n",
    "data_seed=None,\n",
    "dataloader_drop_last=False,\n",
    "dataloader_num_workers=0,\n",
    "dataloader_persistent_workers=False,\n",
    "dataloader_pin_memory=True,\n",
    "dataloader_prefetch_factor=None,\n",
    "ddp_backend=None,\n",
    "ddp_broadcast_buffers=None,\n",
    "ddp_bucket_cap_mb=None,\n",
    "ddp_find_unused_parameters=None,\n",
    "ddp_timeout=1800,\n",
    "debug=[],\n",
    "deepspeed=LLM-quickstart/deepspeed/config/ds_config_zero3.json,\n",
    "disable_tqdm=False,\n",
    "dispatch_batches=None,\n",
    "do_eval=False,\n",
    "do_predict=False,\n",
    "do_train=True,\n",
    "eval_accumulation_steps=None,\n",
    "eval_delay=0,\n",
    "eval_steps=None,\n",
    "evaluation_strategy=no,\n",
    "fp16=False,\n",
    "fp16_backend=auto,\n",
    "fp16_full_eval=False,\n",
    "fp16_opt_level=O1,\n",
    "fsdp=[],\n",
    "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
    "fsdp_min_num_params=0,\n",
    "fsdp_transformer_layer_cls_to_wrap=None,\n",
    "full_determinism=False,\n",
    "generation_config=None,\n",
    "generation_max_length=None,\n",
    "generation_num_beams=None,\n",
    "gradient_accumulation_steps=1,\n",
    "gradient_checkpointing=False,\n",
    "gradient_checkpointing_kwargs=None,\n",
    "greater_is_better=None,\n",
    "group_by_length=False,\n",
    "half_precision_backend=auto,\n",
    "hub_always_push=False,\n",
    "hub_model_id=None,\n",
    "hub_private_repo=False,\n",
    "hub_strategy=every_save,\n",
    "hub_token=<HUB_TOKEN>,\n",
    "ignore_data_skip=False,\n",
    "include_inputs_for_metrics=False,\n",
    "include_num_input_tokens_seen=False,\n",
    "include_tokens_per_second=False,\n",
    "jit_mode_eval=False,\n",
    "label_names=None,\n",
    "label_smoothing_factor=0.0,\n",
    "learning_rate=5e-05,\n",
    "length_column_name=length,\n",
    "load_best_model_at_end=False,\n",
    "local_rank=0,\n",
    "log_level=passive,\n",
    "log_level_replica=warning,\n",
    "log_on_each_node=True,\n",
    "logging_dir=output_dir/runs/Feb11_02-33-00_autodl-container-a5904787c3-9bffb005,\n",
    "logging_first_step=False,\n",
    "logging_nan_inf_filter=True,\n",
    "logging_steps=500,\n",
    "logging_strategy=steps,\n",
    "lr_scheduler_kwargs={},\n",
    "lr_scheduler_type=linear,\n",
    "max_grad_norm=1.0,\n",
    "max_steps=-1,\n",
    "metric_for_best_model=None,\n",
    "mp_parameters=,\n",
    "neftune_noise_alpha=None,\n",
    "no_cuda=False,\n",
    "num_train_epochs=1.0,\n",
    "optim=adamw_torch,\n",
    "optim_args=None,\n",
    "output_dir=output_dir,\n",
    "overwrite_output_dir=True,\n",
    "past_index=-1,\n",
    "per_device_eval_batch_size=8,\n",
    "per_device_train_batch_size=1,\n",
    "predict_with_generate=False,\n",
    "prediction_loss_only=False,\n",
    "push_to_hub=False,\n",
    "push_to_hub_model_id=None,\n",
    "push_to_hub_organization=None,\n",
    "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
    "ray_scope=last,\n",
    "remove_unused_columns=True,\n",
    "report_to=['tensorboard'],\n",
    "resume_from_checkpoint=None,\n",
    "run_name=output_dir,\n",
    "save_on_each_node=False,\n",
    "save_only_model=False,\n",
    "save_safetensors=True,\n",
    "save_steps=500,\n",
    "save_strategy=steps,\n",
    "save_total_limit=None,\n",
    "seed=42,\n",
    "skip_memory_metrics=True,\n",
    "sortish_sampler=False,\n",
    "split_batches=False,\n",
    "tf32=None,\n",
    "torch_compile=False,\n",
    "torch_compile_backend=None,\n",
    "torch_compile_mode=None,\n",
    "torchdynamo=None,\n",
    "tpu_metrics_debug=False,\n",
    "tpu_num_cores=None,\n",
    "use_cpu=False,\n",
    "use_ipex=False,\n",
    "use_legacy_prediction_loop=False,\n",
    "use_mps_device=False,\n",
    "warmup_ratio=0.0,\n",
    "warmup_steps=0,\n",
    "weight_decay=0.0,\n",
    ")\n",
    "02/11/2024 02:33:01 - WARNING - __main__ - You're running a t5 model but didn't provide a source prefix, which is expected, e.g. with `--source_prefix 'translate English to German: ' `\n",
    "Using the latest cached version of the module from /root/autodl-tmp/cache/modules/datasets_modules/datasets/wmt16/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad (last modified on Sun Feb 11 01:20:38 2024) since it couldn't be found locally at wmt16, or remotely on the Hugging Face Hub.\n",
    "02/11/2024 02:33:21 - WARNING - datasets.load - Using the latest cached version of the module from /root/autodl-tmp/cache/modules/datasets_modules/datasets/wmt16/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad (last modified on Sun Feb 11 01:20:38 2024) since it couldn't be found locally at wmt16, or remotely on the Hugging Face Hub.\n",
    "Loading Dataset Infos from /root/autodl-tmp/cache/modules/datasets_modules/datasets/wmt16/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "02/11/2024 02:33:21 - INFO - datasets.info - Loading Dataset Infos from /root/autodl-tmp/cache/modules/datasets_modules/datasets/wmt16/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "Overwrite dataset info from restored data version if exists.\n",
    "02/11/2024 02:33:21 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
    "Loading Dataset info from /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "02/11/2024 02:33:21 - INFO - datasets.info - Loading Dataset info from /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "Found cached dataset wmt16 (/root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad)\n",
    "02/11/2024 02:33:21 - INFO - datasets.builder - Found cached dataset wmt16 (/root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad)\n",
    "Loading Dataset info from /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "02/11/2024 02:33:21 - INFO - datasets.info - Loading Dataset info from /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad\n",
    "[INFO|configuration_utils.py:729] 2024-02-11 02:33:32,049 >> loading configuration file config.json from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/config.json\n",
    "[INFO|configuration_utils.py:792] 2024-02-11 02:33:32,060 >> Model config T5Config {\n",
    "  \"_name_or_path\": \"t5-3b\",\n",
    "  \"architectures\": [\n",
    "    \"T5WithLMHeadModel\"\n",
    "  ],\n",
    "  \"classifier_dropout\": 0.0,\n",
    "  \"d_ff\": 16384,\n",
    "  \"d_kv\": 128,\n",
    "  \"d_model\": 1024,\n",
    "  \"decoder_start_token_id\": 0,\n",
    "  \"dense_act_fn\": \"relu\",\n",
    "  \"dropout_rate\": 0.1,\n",
    "  \"eos_token_id\": 1,\n",
    "  \"feed_forward_proj\": \"relu\",\n",
    "  \"initializer_factor\": 1.0,\n",
    "  \"is_encoder_decoder\": true,\n",
    "  \"is_gated_act\": false,\n",
    "  \"layer_norm_epsilon\": 1e-06,\n",
    "  \"model_type\": \"t5\",\n",
    "  \"n_positions\": 512,\n",
    "  \"num_decoder_layers\": 24,\n",
    "  \"num_heads\": 32,\n",
    "  \"num_layers\": 24,\n",
    "  \"output_past\": true,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"relative_attention_max_distance\": 128,\n",
    "  \"relative_attention_num_buckets\": 32,\n",
    "  \"task_specific_params\": {\n",
    "    \"summarization\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"length_penalty\": 2.0,\n",
    "      \"max_length\": 200,\n",
    "      \"min_length\": 30,\n",
    "      \"no_repeat_ngram_size\": 3,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"summarize: \"\n",
    "    },\n",
    "    \"translation_en_to_de\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to German: \"\n",
    "    },\n",
    "    \"translation_en_to_fr\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to French: \"\n",
    "    },\n",
    "    \"translation_en_to_ro\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to Romanian: \"\n",
    "    }\n",
    "  },\n",
    "  \"transformers_version\": \"4.38.0.dev0\",\n",
    "  \"use_cache\": true,\n",
    "  \"vocab_size\": 32128\n",
    "}\n",
    "\n",
    "[INFO|tokenization_auto.py:607] 2024-02-11 02:33:42,312 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
    "[INFO|configuration_utils.py:729] 2024-02-11 02:33:52,724 >> loading configuration file config.json from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/config.json\n",
    "[INFO|configuration_utils.py:792] 2024-02-11 02:33:52,727 >> Model config T5Config {\n",
    "  \"_name_or_path\": \"t5-3b\",\n",
    "  \"architectures\": [\n",
    "    \"T5WithLMHeadModel\"\n",
    "  ],\n",
    "  \"classifier_dropout\": 0.0,\n",
    "  \"d_ff\": 16384,\n",
    "  \"d_kv\": 128,\n",
    "  \"d_model\": 1024,\n",
    "  \"decoder_start_token_id\": 0,\n",
    "  \"dense_act_fn\": \"relu\",\n",
    "  \"dropout_rate\": 0.1,\n",
    "  \"eos_token_id\": 1,\n",
    "  \"feed_forward_proj\": \"relu\",\n",
    "  \"initializer_factor\": 1.0,\n",
    "  \"is_encoder_decoder\": true,\n",
    "  \"is_gated_act\": false,\n",
    "  \"layer_norm_epsilon\": 1e-06,\n",
    "  \"model_type\": \"t5\",\n",
    "  \"n_positions\": 512,\n",
    "  \"num_decoder_layers\": 24,\n",
    "  \"num_heads\": 32,\n",
    "  \"num_layers\": 24,\n",
    "  \"output_past\": true,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"relative_attention_max_distance\": 128,\n",
    "  \"relative_attention_num_buckets\": 32,\n",
    "  \"task_specific_params\": {\n",
    "    \"summarization\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"length_penalty\": 2.0,\n",
    "      \"max_length\": 200,\n",
    "      \"min_length\": 30,\n",
    "      \"no_repeat_ngram_size\": 3,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"summarize: \"\n",
    "    },\n",
    "    \"translation_en_to_de\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to German: \"\n",
    "    },\n",
    "    \"translation_en_to_fr\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to French: \"\n",
    "    },\n",
    "    \"translation_en_to_ro\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to Romanian: \"\n",
    "    }\n",
    "  },\n",
    "  \"transformers_version\": \"4.38.0.dev0\",\n",
    "  \"use_cache\": true,\n",
    "  \"vocab_size\": 32128\n",
    "}\n",
    "\n",
    "[INFO|tokenization_utils_base.py:2029] 2024-02-11 02:34:13,365 >> loading file spiece.model from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/spiece.model\n",
    "[INFO|tokenization_utils_base.py:2029] 2024-02-11 02:34:13,365 >> loading file tokenizer.json from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/tokenizer.json\n",
    "[INFO|tokenization_utils_base.py:2029] 2024-02-11 02:34:13,366 >> loading file added_tokens.json from cache at None\n",
    "[INFO|tokenization_utils_base.py:2029] 2024-02-11 02:34:13,366 >> loading file special_tokens_map.json from cache at None\n",
    "[INFO|tokenization_utils_base.py:2029] 2024-02-11 02:34:13,366 >> loading file tokenizer_config.json from cache at None\n",
    "[INFO|configuration_utils.py:729] 2024-02-11 02:34:13,366 >> loading configuration file config.json from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/config.json\n",
    "[INFO|configuration_utils.py:792] 2024-02-11 02:34:13,380 >> Model config T5Config {\n",
    "  \"_name_or_path\": \"t5-3b\",\n",
    "  \"architectures\": [\n",
    "    \"T5WithLMHeadModel\"\n",
    "  ],\n",
    "  \"classifier_dropout\": 0.0,\n",
    "  \"d_ff\": 16384,\n",
    "  \"d_kv\": 128,\n",
    "  \"d_model\": 1024,\n",
    "  \"decoder_start_token_id\": 0,\n",
    "  \"dense_act_fn\": \"relu\",\n",
    "  \"dropout_rate\": 0.1,\n",
    "  \"eos_token_id\": 1,\n",
    "  \"feed_forward_proj\": \"relu\",\n",
    "  \"initializer_factor\": 1.0,\n",
    "  \"is_encoder_decoder\": true,\n",
    "  \"is_gated_act\": false,\n",
    "  \"layer_norm_epsilon\": 1e-06,\n",
    "  \"model_type\": \"t5\",\n",
    "  \"n_positions\": 512,\n",
    "  \"num_decoder_layers\": 24,\n",
    "  \"num_heads\": 32,\n",
    "  \"num_layers\": 24,\n",
    "  \"output_past\": true,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"relative_attention_max_distance\": 128,\n",
    "  \"relative_attention_num_buckets\": 32,\n",
    "  \"task_specific_params\": {\n",
    "    \"summarization\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"length_penalty\": 2.0,\n",
    "      \"max_length\": 200,\n",
    "      \"min_length\": 30,\n",
    "      \"no_repeat_ngram_size\": 3,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"summarize: \"\n",
    "    },\n",
    "    \"translation_en_to_de\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to German: \"\n",
    "    },\n",
    "    \"translation_en_to_fr\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to French: \"\n",
    "    },\n",
    "    \"translation_en_to_ro\": {\n",
    "      \"early_stopping\": true,\n",
    "      \"max_length\": 300,\n",
    "      \"num_beams\": 4,\n",
    "      \"prefix\": \"translate English to Romanian: \"\n",
    "    }\n",
    "  },\n",
    "  \"transformers_version\": \"4.38.0.dev0\",\n",
    "  \"use_cache\": true,\n",
    "  \"vocab_size\": 32128\n",
    "}\n",
    "\n",
    "/root/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
    "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
    "- Be aware that you SHOULD NOT rely on t5-3b automatically truncating your input to 512 when padding/encoding.\n",
    "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
    "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
    "  warnings.warn(\n",
    "[INFO|modeling_utils.py:3259] 2024-02-11 02:34:13,717 >> loading weights file model.safetensors from cache at /root/autodl-tmp/transform_cache/models--t5-3b/snapshots/bed96aab9ee46012a5046386105ee5fd0ac572f0/model.safetensors\n",
    "[INFO|modeling_utils.py:3365] 2024-02-11 02:34:13,743 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
    "[INFO|configuration_utils.py:840] 2024-02-11 02:34:13,753 >> Generate config GenerationConfig {\n",
    "  \"decoder_start_token_id\": 0,\n",
    "  \"eos_token_id\": 1,\n",
    "  \"pad_token_id\": 0\n",
    "}\n",
    "\n",
    "[2024-02-11 02:34:18,735] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 510, num_elems = 2.88B\n",
    "[INFO|modeling_utils.py:3992] 2024-02-11 02:34:21,579 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
    "\n",
    "[INFO|modeling_utils.py:4000] 2024-02-11 02:34:21,579 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-3b.\n",
    "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
    "[INFO|modeling_utils.py:3546] 2024-02-11 02:34:31,781 >> Generation config file not found, using a generation config created from the model config.\n",
    "[INFO|modeling_utils.py:1875] 2024-02-11 02:34:31,796 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32100. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
    "Loading cached processed dataset at /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad/cache-d11b78484a2e05f1.arrow\n",
    "02/11/2024 02:34:32 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/autodl-tmp/datasets_cache/wmt16/ro-en/1.0.0/f5dc442f4d1c2cc487cd2d5591af56c03a5f03bb98a3bb92151d015c8c9cb7ad/cache-d11b78484a2e05f1.arrow\n",
    "02/11/2024 02:36:37 - WARNING - evaluate.loading - Using the latest cached version of the module from /root/autodl-tmp/cache/modules/evaluate_modules/metrics/evaluate-metric--sacrebleu/28676bf65b4f88b276df566e48e603732d0b4afd237603ebdf92acaacf5be99b (last modified on Sun Feb 11 01:33:07 2024) since it couldn't be found locally at evaluate-metric--sacrebleu, or remotely on the Hugging Face Hub.\n",
    "[INFO|trainer.py:586] 2024-02-11 02:36:37,161 >> Using auto half precision backend\n",
    "[2024-02-11 02:36:37,360] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.13.2+25a02047, git-hash=25a02047, git-branch=master\n",
    "[2024-02-11 02:36:37,388] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
    "Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
    "Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
    "[2024-02-11 02:36:39,147] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
    "[2024-02-11 02:36:39,147] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
    "[2024-02-11 02:36:39,215] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
    "[2024-02-11 02:36:39,215] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
    "[2024-02-11 02:36:39,215] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
    "[2024-02-11 02:36:39,215] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer\n",
    "[2024-02-11 02:36:39,347] [INFO] [utils.py:800:see_memory_usage] Stage 3 initialize beginning\n",
    "[2024-02-11 02:36:39,348] [INFO] [utils.py:801:see_memory_usage] MA 0.06 GB         Max_MA 0.18 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:39,348] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 46.58 GB, percent = 4.6%\n",
    "[2024-02-11 02:36:39,355] [INFO] [stage3.py:130:__init__] Reduce bucket size 1048576\n",
    "[2024-02-11 02:36:39,355] [INFO] [stage3.py:131:__init__] Prefetch bucket size 16\n",
    "[2024-02-11 02:36:39,474] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
    "[2024-02-11 02:36:39,475] [INFO] [utils.py:801:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:39,475] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 46.58 GB, percent = 4.6%\n",
    "Parameter Offload: Total persistent parameters: 126976 in 124 params\n",
    "[2024-02-11 02:36:39,700] [INFO] [utils.py:800:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
    "[2024-02-11 02:36:39,701] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.06 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:39,702] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 46.58 GB, percent = 4.6%\n",
    "[2024-02-11 02:36:39,828] [INFO] [utils.py:800:see_memory_usage] Before creating fp16 partitions\n",
    "[2024-02-11 02:36:39,829] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:39,829] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 46.58 GB, percent = 4.6%\n",
    "[2024-02-11 02:36:43,561] [INFO] [utils.py:800:see_memory_usage] After creating fp16 partitions: 3\n",
    "[2024-02-11 02:36:43,562] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:43,562] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 54.78 GB, percent = 5.4%\n",
    "[2024-02-11 02:36:43,666] [INFO] [utils.py:800:see_memory_usage] Before creating fp32 partitions\n",
    "[2024-02-11 02:36:43,666] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:43,667] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 54.78 GB, percent = 5.4%\n",
    "[2024-02-11 02:36:44,853] [INFO] [utils.py:800:see_memory_usage] After creating fp32 partitions\n",
    "[2024-02-11 02:36:44,854] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:44,854] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 67.23 GB, percent = 6.7%\n",
    "[2024-02-11 02:36:44,955] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
    "[2024-02-11 02:36:44,955] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:44,955] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 67.23 GB, percent = 6.7%\n",
    "[2024-02-11 02:36:53,404] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
    "[2024-02-11 02:36:53,405] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.06 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:53,405] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 100.72 GB, percent = 10.0%\n",
    "[2024-02-11 02:36:53,406] [INFO] [stage3.py:487:_setup_for_real_optimizer] optimizer state initialized\n",
    "[2024-02-11 02:36:57,802] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
    "[2024-02-11 02:36:57,803] [INFO] [utils.py:801:see_memory_usage] MA 0.0 GB         Max_MA 0.12 GB         CA 0.19 GB         Max_CA 0 GB \n",
    "[2024-02-11 02:36:57,803] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 108.91 GB, percent = 10.8%\n",
    "[2024-02-11 02:36:57,803] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
    "[2024-02-11 02:36:57,803] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
    "[2024-02-11 02:36:57,803] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f31782a3130>\n",
    "[2024-02-11 02:36:57,803] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]\n",
    "[2024-02-11 02:36:57,805] [INFO] [config.py:987:print] DeepSpeedEngine configuration:\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   activation_checkpointing_config  {\n",
    "    \"partition_activations\": false, \n",
    "    \"contiguous_memory_optimization\": false, \n",
    "    \"cpu_checkpointing\": false, \n",
    "    \"number_checkpoints\": null, \n",
    "    \"synchronize_checkpoint_boundary\": false, \n",
    "    \"profile\": false\n",
    "}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   amp_enabled .................. False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   amp_params ................... False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   autotuning_config ............ {\n",
    "    \"enabled\": false, \n",
    "    \"start_step\": null, \n",
    "    \"end_step\": null, \n",
    "    \"metric_path\": null, \n",
    "    \"arg_mappings\": null, \n",
    "    \"metric\": \"throughput\", \n",
    "    \"model_info\": null, \n",
    "    \"results_dir\": \"autotuning_results\", \n",
    "    \"exps_dir\": \"autotuning_exps\", \n",
    "    \"overwrite\": true, \n",
    "    \"fast\": true, \n",
    "    \"start_profile_step\": 3, \n",
    "    \"end_profile_step\": 5, \n",
    "    \"tuner_type\": \"gridsearch\", \n",
    "    \"tuner_early_stopping\": 5, \n",
    "    \"tuner_num_trials\": 50, \n",
    "    \"model_info_path\": null, \n",
    "    \"mp_size\": 1, \n",
    "    \"max_train_batch_size\": null, \n",
    "    \"min_train_batch_size\": 1, \n",
    "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
    "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
    "    \"num_tuning_micro_batch_sizes\": 3\n",
    "}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   bfloat16_enabled ............. True\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   checkpoint_parallel_write_pipeline  False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   checkpoint_tag_validation_enabled  True\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   checkpoint_tag_validation_fail  False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f31a01a9bd0>\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   communication_data_type ...... None\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   curriculum_enabled_legacy .... False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   curriculum_params_legacy ..... False\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
    "[2024-02-11 02:36:57,806] [INFO] [config.py:991:print]   data_efficiency_enabled ...... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   dataloader_drop_last ......... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   disable_allgather ............ False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   dump_state ................... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   dynamic_loss_scale_args ...... None\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_enabled ........... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_gas_boundary_resolution  1\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_layer_num ......... 0\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_max_iter .......... 100\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_stability ......... 1e-06\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_tol ............... 0.01\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   eigenvalue_verbose ........... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   elasticity_enabled ........... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   flops_profiler_config ........ {\n",
    "    \"enabled\": false, \n",
    "    \"recompute_fwd_factor\": 0.0, \n",
    "    \"profile_step\": 1, \n",
    "    \"module_depth\": -1, \n",
    "    \"top_modules\": 1, \n",
    "    \"detailed\": true, \n",
    "    \"output_file\": null\n",
    "}\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   fp16_auto_cast ............... None\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   fp16_enabled ................. False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   fp16_master_weights_and_gradients  False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   global_rank .................. 0\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   grad_accum_dtype ............. None\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   gradient_accumulation_steps .. 1\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   gradient_clipping ............ 1.0\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   gradient_predivide_factor .... 1.0\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   graph_harvesting ............. False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   initial_dynamic_scale ........ 1\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   load_universal_checkpoint .... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   loss_scale ................... 1.0\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   memory_breakdown ............. False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   mics_hierarchial_params_gather  False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   mics_shard_size .............. -1\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   nebula_config ................ {\n",
    "    \"enabled\": false, \n",
    "    \"persistent_storage_path\": null, \n",
    "    \"persistent_time_interval\": 100, \n",
    "    \"num_of_version_in_retention\": 2, \n",
    "    \"enable_nebula_load\": true, \n",
    "    \"load_path\": null\n",
    "}\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   optimizer_legacy_fusion ...... False\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   optimizer_name ............... adamw\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
    "[2024-02-11 02:36:57,807] [INFO] [config.py:991:print]   pld_enabled .................. False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   pld_params ................... False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   prescale_gradients ........... False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   scheduler_name ............... WarmupLR\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 0}\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   seq_parallel_communication_data_type  torch.float32\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   sparse_attention ............. None\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   sparse_gradients_enabled ..... False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   steps_per_print .............. inf\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   train_batch_size ............. 1\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   train_micro_batch_size_per_gpu  1\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   use_data_before_expert_parallel_  False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   use_node_local_storage ....... False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   wall_clock_breakdown ......... False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   weight_quantization_config ... None\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   world_size ................... 1\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   zero_allow_untested_optimizer  False\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=1048576 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=16 param_persistence_threshold=20000 model_persistence_threshold=sys.maxsize max_live_parameters=5000 max_reuse_distance=5000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   zero_enabled ................. True\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   zero_force_ds_cpu_optimizer .. True\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:991:print]   zero_optimization_stage ...... 3\n",
    "[2024-02-11 02:36:57,808] [INFO] [config.py:977:print_user_config]   json = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": false, \n",
    "        \"loss_scale\": 0, \n",
    "        \"loss_scale_window\": 1000, \n",
    "        \"initial_scale_power\": 16, \n",
    "        \"hysteresis\": 2, \n",
    "        \"min_loss_scale\": 1\n",
    "    }, \n",
    "    \"bf16\": {\n",
    "        \"enabled\": true\n",
    "    }, \n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\", \n",
    "        \"params\": {\n",
    "            \"lr\": 5e-05, \n",
    "            \"betas\": [0.9, 0.999], \n",
    "            \"eps\": 1e-08, \n",
    "            \"weight_decay\": 0.0\n",
    "        }\n",
    "    }, \n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\", \n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": 0, \n",
    "            \"warmup_max_lr\": 5e-05, \n",
    "            \"warmup_num_steps\": 0\n",
    "        }\n",
    "    }, \n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3, \n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\", \n",
    "            \"pin_memory\": true\n",
    "        }, \n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\", \n",
    "            \"pin_memory\": true\n",
    "        }, \n",
    "        \"overlap_comm\": true, \n",
    "        \"contiguous_gradients\": true, \n",
    "        \"sub_group_size\": 1.000000e+09, \n",
    "        \"reduce_bucket_size\": 1.048576e+06, \n",
    "        \"stage3_prefetch_bucket_size\": 16, \n",
    "        \"stage3_param_persistence_threshold\": 2.000000e+04, \n",
    "        \"stage3_max_live_parameters\": 5.000000e+03, \n",
    "        \"stage3_max_reuse_distance\": 5.000000e+03, \n",
    "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
    "    }, \n",
    "    \"gradient_accumulation_steps\": 1, \n",
    "    \"gradient_clipping\": 1.0, \n",
    "    \"steps_per_print\": inf, \n",
    "    \"train_batch_size\": 1, \n",
    "    \"train_micro_batch_size_per_gpu\": 1, \n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "[INFO|trainer.py:1747] 2024-02-11 02:36:57,808 >> ***** Running training *****\n",
    "[INFO|trainer.py:1748] 2024-02-11 02:36:57,808 >>   Num examples = 500\n",
    "[INFO|trainer.py:1749] 2024-02-11 02:36:57,809 >>   Num Epochs = 1\n",
    "[INFO|trainer.py:1750] 2024-02-11 02:36:57,809 >>   Instantaneous batch size per device = 1\n",
    "[INFO|trainer.py:1753] 2024-02-11 02:36:57,809 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
    "[INFO|trainer.py:1754] 2024-02-11 02:36:57,809 >>   Gradient Accumulation steps = 1\n",
    "[INFO|trainer.py:1755] 2024-02-11 02:36:57,809 >>   Total optimization steps = 500\n",
    "[INFO|trainer.py:1756] 2024-02-11 02:36:57,811 >>   Number of trainable parameters = 2,851,569,664\n",
    "  0%|                                                                                                                 | 0/500 [00:00<?, ?it/s]/root/miniconda3/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py:1403: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
    "    total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])\n",
    "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [47:32<00:00,  5.71s/it]\n",
    "[WARNING|trainer.py:2920] 2024-02-11 15:36:37,574 >>  stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights\n",
    "[INFO|trainer.py:2981] 2024-02-11 15:36:37,574 >> Saving model checkpoint to autodl-tmp/output_dir\n",
    "[INFO|configuration_utils.py:473] 2024-02-11 15:36:37,575 >> Configuration saved in autodl-tmp/output_dir/config.json\n",
    "[INFO|configuration_utils.py:608] 2024-02-11 15:36:37,576 >> Configuration saved in autodl-tmp/output_dir/generation_config.json\n",
    "[INFO|modeling_utils.py:2454] 2024-02-11 15:36:37,576 >> Model weights saved in autodl-tmp/output_dir/model.safetensors\n",
    "[INFO|tokenization_utils_base.py:2435] 2024-02-11 15:36:37,578 >> tokenizer config file saved in autodl-tmp/output_dir/tokenizer_config.json\n",
    "[INFO|tokenization_utils_base.py:2444] 2024-02-11 15:36:37,578 >> Special tokens file saved in autodl-tmp/output_dir/special_tokens_map.json\n",
    "[INFO|tokenization_t5_fast.py:191] 2024-02-11 15:36:37,579 >> Copy vocab file to autodl-tmp/output_dir/spiece.model\n",
    "[2024-02-11 15:36:37,609] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!\n",
    "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
    "  warnings.warn(\n",
    "[2024-02-11 15:36:37,627] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: autodl-tmp/output_dir/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
    "[2024-02-11 15:36:37,627] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving autodl-tmp/output_dir/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...\n",
    "[2024-02-11 15:36:37,650] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved autodl-tmp/output_dir/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.\n",
    "[2024-02-11 15:36:37,651] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving autodl-tmp/output_dir/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
    "[2024-02-11 15:37:17,127] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved autodl-tmp/output_dir/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
    "[2024-02-11 15:37:17,128] [INFO] [engine.py:3487:_save_zero_checkpoint] zero checkpoint saved autodl-tmp/output_dir/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
    "[2024-02-11 15:37:17,138] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!\n",
    "***** train metrics *****\n",
    "  epoch                    =        1.0\n",
    "  train_loss               =      0.558\n",
    "  train_runtime            = 0:47:32.65\n",
    "  train_samples            =        500\n",
    "  train_samples_per_second =      0.175\n",
    "  train_steps_per_second   =      0.175\n",
    "[INFO|modelcard.py:452] 2024-02-11 15:37:17,935 >> Dropping the following result as it does not have all the necessary fields:\n",
    "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'wmt16 ro-en', 'type': 'wmt16', 'config': 'ro-en', 'split': 'train', 'args': 'ro-en'}}\n",
    "[2024-02-11 15:37:29,404] [INFO] [launch.py:348:main] Process 1169 exits successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602313e-faed-478b-909c-a7fee484fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "内存占用\n",
    "Every 1.0s: nvidia-smi                                                          autodl-container-a5904787c3-9bffb005: Sun Feb 11 02:40:19 2024\n",
    "\n",
    "Sun Feb 11 02:40:19 2024\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:32:00.0 Off |                  Off |\n",
    "|  0%   44C    P2              71W / 450W |   1911MiB / 24564MiB |     41%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "+---------------------------------------------------------------------------------------+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
